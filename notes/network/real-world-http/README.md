# Real World HTTP ―歴史とコードに学ぶインターネットとウェブ技術

[code](https://github.com/1keiuu/playground/tree/main/go/rw_http)

- [1章 HTTP/1.0の世界:基本となる4つの要素](#1章-http10の世界基本となる4つの要素)  
- [2章 HTTP/1.0のセマンティクス:ブラウザの基本機能の裏側](#2章-http10のセマンティクスブラウザの基本機能の裏側)  
- [3章 Go言語によるHTTP/1.0クライアントの実装](#3章-Go言語によるhttp10クライアントの実装)  
- [4章 HTTP/1.1のシンタックス:高速化と安全性を求めた拡張](#4章-http11のシンタックス高速化と安全性を求めた拡張)  
- [5章 HTTP/1.1のセマンティクス:広がるのHTTPの用途](#5章-http11のセマンティクス広がるのhttpの用途)  
- [6章 Go言語によるHTTP1.1クライアントの実装](#6章-Go言語によるhttp11クライアントの実装)  
- [7章 HTTP/2、HTTP/3のシンタックス:プロトコルの再定義](#7章-HTTP2HTTP3のシンタックスhttpプロトコルの再定義)
- [8章 HTTP/2のセマンティクス:新しいユースケース](#8章-http2のセマンティクス新しいユースケース)
- [9章 Go言語によるHTTP/2、HTML5のプロトコルの実装](#9章-go言語によるhttp2html5のプロトコルの実装)
- [10章 クライアント視点で見るRESTful API](#10章-クライアント視点で見るrestful-api)
- [11章 JavaScriptによるブラウザからの動的なHTTPリクエスト](#11章-javaScriptによるブラウザからの動的なhttpリクエスト)
- [12章 ウェブアプリケーションの基礎](#12章-ウェブアプリケーションの基礎)
- [13章 クラウド時代のHTTP:ウェブを強くするさまざまな技術](#13章-クラウド時代のhttpウェブを強くするさまざまな技術)
- [14章 セキュリティ:ブラウザを守るHTTPの機能](#14章-セキュリティブラウザを守るhttpの機能)

## まえがき
- 基本的にはすでに確立されていて、かつ使われている技術を紹介
    - WebTransport,gRP,GraphQLなどは割愛 
- 歴史を学ぼう
    - 歴史を知ればその技術をどう使っていけばいいかが分かり、設計を選択する場面でも活きる
    - http0.9から学ぶ事で、根幹の機能を知り、追加で必要になっていった機能が段階的に理解できる。
- curlを使ってくよ(1997年製で20年近く開発されてる)
    - curlと似たような事ができる`wget`はダウンロードしたHTMLを解析して、リンクされている画像などもまとめてダウンロードできる(curlは出来ない)
- Goの日本での普及は特殊
    - 技術書や大規模なイベントが少ないにも関わらず盛り上がってる
    - 理由: 他の言語を知っている人から読みやすい/パフォーマンスが高く、型安全でもあり移行したときのメリットが明確/使い勝手がいい


## 1章 HTTP/1.0の世界:基本となる4つの要素
- RFC(request for comment)はIEFTによって作られた、通信の相互接続性を維持するために共通化された仕様書
- ブラウザに特化した仕様策定はW3C(World Wide Web Consortium)へ移された

- 最低限のwebServerを作成してhttp0.9を再現する ([code](https://github.com/1keiuu/playground/blob/main/go/rw_http/main.go))
    - サーバー: `go run main.go`
    - リクエスト: `curl --http1.0 http://localhost:8888`
    - 完全にhttp0.9を再現するには難しい。pythonのhttpServerは対応してる。
    - 0.9はドキュメント(HTML)を取得する機能しかなかった。
    - 欠点:   
        - 1つのドキュメントしか扱えない。
        - 検索のリクエスト(現在のパラメータ)以外のリクエストを送信できなかった。
        - 新しい文書の送信、更新、削除はできなかった。
        - サーバーが正しく応答を返すことができたかも分からない。
        - HTML前提だったため、サーバーからコンテンツのフォーマットを指定できない。

- 0.9から1.0へ移行する前の、名前のないバージョン(1.0とほぼ同じ)は電子メールのプロトコルなどを取り込んで行った。
    - リクエストにメソッド(GET)の追加
    - httpのバージョンが追加
    - ヘッダーが追加された(Host,User-Agent,Accept)
    - http Statusが追加された

- ヘッダーの仕組みはメールをベースに作られてる
- ブラウザがコンテンツの内容からContent-Typeを推測する → Content Sniffing
    - セキュリティホールになるのでオフにするのが現代の主流
        `X-Content-Type-Options: nosniff`
    - 例)
    ```
    HTTP/1.1 200 OK
    Content-Type: text/plain
    <br/>
    これはテキストファイルです。
    <script>alert("xss");</script>
    ```
    IEなどのブラウザはContent-Type:text/plainを無視してHTMLだと判断し、スクリプトが実行される
- マスター/スレーブ構成
    - 複数の機器を連携してシステムなどを動作させるにあたり、そのうちのひとつに全ての管理・制御を担当する「マスター」という役割をあて、残りをマスターに制御させる「スレーブ」とする方式
    - 主にデータベースサーバで行われる方式で、この場合、平常時はマスターがデータ読み込み・書き込みといった各処理を行い、スレーブはマスターの制御によって主にマスターのデータの複製（バックアップ）を行う。そしてマスターに障害が発生した際は、スレーブの中のひとつがマスターに切り替わって処理を継続する。
    - [引用]](https://www.fielding.co.jp/column/it_words/202003_1/#:~:text=%E2%91%A2%E3%83%9E%E3%82%B9%E3%82%BF%E3%83%BC%2F%E3%82%B9%E3%83%AC%E3%83%BC%E3%83%96%E6%A7%8B%E6%88%90,%E3%80%8C%E3%82%B9%E3%83%AC%E3%83%BC%E3%83%96%E3%80%8D%E3%81%A8%E3%81%99%E3%82%8B%E6%96%B9%E5%BC%8F%E3%80%82&text=%E3%81%9D%E3%81%97%E3%81%A6%E3%83%9E%E3%82%B9%E3%82%BF%E3%83%BC%E3%81%AB%E9%9A%9C%E5%AE%B3%E3%81%8C,%E3%81%A6%E5%87%A6%E7%90%86%E3%82%92%E7%B6%99%E7%B6%9A%E3%81%99%E3%82%8B%E3%80%82)
- HTTPメソッドは最初は沢山あった。1.0になって結構減った。LINKとかは1.1になってなくなった。
    - HTTP1.0で使われ、現在も残っている物
        - GET
        - HEAD
        - POST
        - PUT
        - DELETE
- RFCで定義されていない非標準のStatusコードがある
    - 444 Nginxがネットワークで問題があったときにエラーログへ吐くStatusコード
    - 999 Yahooがアクセスが増えた時にスクレイピングを禁止する(?)為にエラーを吐くときのコード
## 2章 HTTP/1.0のセマンティクス:ブラウザの基本機能の裏側
- FormのContent-Typeには`application/x-www-form-urlencoded` と `multipart/form-data`がある
    -　前者が普通のフォーム、後者はファイルが含まれている場合
- GETのパラメータが長い場合にURLの制限文字数を超えてしまう&アクセスログに全て残ってしまう
    - → サーバはリダイレクトさせ、リダイレクト先のHTMLに `<input type="hidden"/>`の形で渡す
    - SOAP形式、SAML認証、OpenID Connectなどで使われる方法
- コンテントネゴシエーション
    - 一つのリクエストの中でクライアントとサーバーがヘッダーを使って最適な設定を共有する仕組み
    - ex) ネゴシエーション対象: MIMEタイプ
            リクエストヘッダー: `Accept` ⇄ レスポンスヘッダ: `Content-Type`
    - その他、Accept-系とContent-系は相互に対応している (Accept-LanguageとContent-Languageなど)
- コンテンツ圧縮による通信速度向上は1992年の時点で定義されていた
    - コンテンツの圧縮-展開の速度は通信にかかる時間よりも少ないので全体的な通信速度が向上する
    - 利用料金にも影響していた。(ADSLや光回線が普及する前にはダイアルアップ回線による時間単位の従量課金性だった。現代のモバイル通信も従量課金性なので、圧縮によるデータ量削減は料金に影響する)
    - コンテンツ圧縮はヘッダー内だけで完結する。
        - クライアント側で受け入れ可能な圧縮形式を設定: `Accept-Encoding: deflate, gzip`
        - サーバーは送られてきたリストから、対応できるものがあれば圧縮、または事前に圧縮したコンテンツを返す: `Content-Encoding: gzip`
    - Googleはgzipよりも効率のいい`Brotli`を開発。
    - 圧縮の形式は、クライアント(ブラウザ)、サーバー、使われている言語の全てが対応していなければいけない。どれかが対応していない場合は他の形式にフォールバックされる(おそらくgzip)
- cookie: サーバーからクライアント(ブラウザ)にデータを保存しておいてもらう仕組み
    - サーバーからのレスポンスヘッダー: `Set-Cookie: LAST_ACCESS_DATE=Jul/31/2016`
    - クライアントのリクエストヘッダー(次回移行アクセス時): `Cookie: LAST_ACCESS_DATE=Jul/31/2016`
    - ステートレス(いつ誰がアクセスしてもリクエストが同じなら結果は同じ)なHTTPがあたかもステートフルに見せる仕組み
    - CookieはHTMLページだけでなく、そのページが参照している画像やXMLHttpRequestのレスポンスでも保存できる。
    - 別ドメインの画像ファイルやスクリプトを読み込んだ時に、そのCookieを受け入れるかどうかには制限がある(サードパーティCookie)
    - 発行元が訪れたサイト(ファーストパーティ)かそれ以外のサイト(サードパーティ)の二種類
    - ブラウザを閉じたら消えてしまうセッションクッキーと、期限が設定されていてブラウザを閉じても残る永続クッキーの2種類
    - クッキーはリクエスト時に毎回ヘッダーに設定される為、リクエスト、レスポンスの通信速度に影響する。最大要領は4KBにすべきとRFCにある。
    - セキュリティを高める為にヘッダーで制約を与える
        - Expires,Max-Age
            - Cookieの寿命。Max-Ageは秒。　
            - どちらも設定しなければ`セッションクッキー`
        - secure
            - https以外での通信ではクライアントからサーバーへクッキーを送らないようにする
- Basic認証/Digest認証
    - Basic:ユーザー名とパスワードをbase64エンコーディングする
    - Digest: ハッシュ関数(A→Bは簡単だが、B→Aは簡単に変換できない)を利用する
    - これらがあまり使われていない理由
        - 「特定のフォルダ以下を見せない」という使い方しかできず、ユーザーごとに表示する情報を変えるというのがやりづらい
        - 毎回の計算量が多い(Digestは特に)
        - 明示的なログオフができない
        - ログイン端末の識別ができない
- Cache-Control　~本当にキャッシュしないのは`no-store`のみ~
    - `public`: 同一コンピュータの複数ユーザ間でキャッシュの再利用を許可
    - `privte`: 同一コンピュータを使う別のユーザー間でキャッシュを再利用しない。
    - `max-age=n`: キャッシュの鮮度を秒で指定。86400を指定すると1日間の指定。それ以降は304　NotModifiedが帰って来た時のみキャッシュを利用する。
    - `no-cache`: キャッシュが有効かどうか毎回サーバーに問い合わせる。304　NotModifiedが帰って来た時のみキャッシュを利用する。max-age=0とほぼ同じ
    - `no-store`: キャッシュしない
    - `immutable`: コンテンツが決して変化しないことを伝える。Chrome非対応。
- Vary
    - PCで初回アクセス→キャッシュが保存される→2回目はSPでアクセス→SPではデバイス判別が行われず、キャッシュされたPC用HTMLが返されてしまう
    - ↑はググールのインデックス時にも発生してしまい、SEOにも影響する
    - Varyヘッダーをつけておけば、pc表示/SP表示が存在し、USerAgentにより切り替わることをブラウザ、クローラーに伝えることができる
- Referer
    - ユーザーがどの経路からウェブサイトへ到達したかをサーバーが把握する為に、クライアントがサーバーへ送るヘッダー 
    - Refererの設定の方法は三通りある
        - `Referer-Policy`ヘッダー: 
        - `<meta name="referer" content="設定値"`
        - `<a>`タグなどいくつかの要素の`refererpolicy`属性及、`rel="noreferer"`属性
        設定できる値
            - `no-referer`: 一切送らない
            - `no-referer-when-downgrade`: デフォルト動作と同じで、HTTPS→HTTPの時は送信しない
            - `same-origin`: 同一ドメイン内のリンクに対してのみ、リファラーを送信
            - `origin`: 詳細ページではなく、トップページからリンクされた物としてドメイン名だけを送信
                ex) amebloから楽天リンクを踏んだ時:`referer: https://ameblo.jp/` 
                `Referrer Policy: origin`が設定されている為、amebloのどの記事かは分からない
            - `strict-origin`: originと同じだが、HTTPS→HTTP時には送信しない
            - `origin-when-crossorigin`: 同じドメイン内ではフルのリファラーを、別ドメインではトップのドメイン名だけ表示
            - `strict-origin-when-crossorigin`: `origin-when-crossorigin`と同じだが、HTTPS→HTTP時には送信しない
            - `unsafe-url`: 常に送信
        - この他に、`Content-Security-Policy`でも設定できる
            ex) `Content-Security-Policy: referer origin`
            Content-Security-Policyは数多くのセキュリティに関する設定を一括で変更できるヘッダー
            
## 3章 Go言語によるHTTP/1.0クライアントの実装
## 4章 HTTP/1.1のシンタックス:高速化と安全性を求めた拡張
## 5章 HTTP/1.1のセマンティクス:広がるのHTTPの用途
## 6章 Go言語によるHTTP1.1クライアントの実装
## 7章 HTTP/2、HTTP/3のシンタックス:プロトコルの再定義
## 8章 HTTP/2のセマンティクス:新しいユースケース
## 9章 Go言語によるHTTP/2、HTML5のプロトコルの実装
## 10章 クライアント視点で見るRESTful API
## 11章 JavaScriptによるブラウザからの動的なHTTPリクエスト
## 12章 ウェブアプリケーションの基礎
## 13章 クラウド時代のHTTP:ウェブを強くするさまざまな技術
## 14章 セキュリティ:ブラウザを守るHTTPの機能