# Real World HTTP ―歴史とコードに学ぶインターネットとウェブ技術

[code](https://github.com/1keiuu/playground/tree/main/go/rw_http)

- [1章 HTTP/1.0の世界:基本となる4つの要素](#1章-http10の世界基本となる4つの要素)  
- [2章 HTTP/1.0のセマンティクス:ブラウザの基本機能の裏側](#2章-http10のセマンティクスブラウザの基本機能の裏側)  
- [3章 Go言語によるHTTP/1.0クライアントの実装](#3章-Go言語によるhttp10クライアントの実装)  
- [4章 HTTP/1.1のシンタックス:高速化と安全性を求めた拡張](#4章-http11のシンタックス高速化と安全性を求めた拡張)  
- [5章 HTTP/1.1のセマンティクス:広がるのHTTPの用途](#5章-http11のセマンティクス広がるのhttpの用途)  
- [6章 Go言語によるHTTP1.1クライアントの実装](#6章-Go言語によるhttp11クライアントの実装)  
- [7章 HTTP/2、HTTP/3のシンタックス:プロトコルの再定義](#7章-HTTP2HTTP3のシンタックスhttpプロトコルの再定義)
- [8章 HTTP/2のセマンティクス:新しいユースケース](#8章-http2のセマンティクス新しいユースケース)
- [9章 Go言語によるHTTP/2、HTML5のプロトコルの実装](#9章-go言語によるhttp2html5のプロトコルの実装)
- [10章 クライアント視点で見るRESTful API](#10章-クライアント視点で見るrestful-api)
- [11章 JavaScriptによるブラウザからの動的なHTTPリクエスト](#11章-javaScriptによるブラウザからの動的なhttpリクエスト)
- [12章 ウェブアプリケーションの基礎](#12章-ウェブアプリケーションの基礎)
- [13章 クラウド時代のHTTP:ウェブを強くするさまざまな技術](#13章-クラウド時代のhttpウェブを強くするさまざまな技術)
- [14章 セキュリティ:ブラウザを守るHTTPの機能](#14章-セキュリティブラウザを守るhttpの機能)

## まえがき
- 基本的にはすでに確立されていて、かつ使われている技術を紹介
    - WebTransport,gRP,GraphQLなどは割愛 
- 歴史を学ぼう
    - 歴史を知ればその技術をどう使っていけばいいかが分かり、設計を選択する場面でも活きる
    - http0.9から学ぶ事で、根幹の機能を知り、追加で必要になっていった機能が段階的に理解できる。
- curlを使ってくよ(1997年製で20年近く開発されてる)
    - curlと似たような事ができる`wget`はダウンロードしたHTMLを解析して、リンクされている画像などもまとめてダウンロードできる(curlは出来ない)
- Goの日本での普及は特殊
    - 技術書や大規模なイベントが少ないにも関わらず盛り上がってる
    - 理由: 他の言語を知っている人から読みやすい/パフォーマンスが高く、型安全でもあり移行したときのメリットが明確/使い勝手がいい


## 1章 HTTP/1.0の世界:基本となる4つの要素
- RFC(request for comment)はIEFTによって作られた、通信の相互接続性を維持するために共通化された仕様書
- ブラウザに特化した仕様策定はW3C(World Wide Web Consortium)へ移された

- 最低限のwebServerを作成してhttp0.9を再現する ([code](https://github.com/1keiuu/playground/blob/main/go/rw_http/main.go))
    - サーバー: `go run main.go`
    - リクエスト: `curl --http1.0 http://localhost:8888`
    - 完全にhttp0.9を再現するには難しい。pythonのhttpServerは対応してる。
    - 0.9はドキュメント(HTML)を取得する機能しかなかった。
    - 欠点:   
        - 1つのドキュメントしか扱えない。
        - 検索のリクエスト(現在のパラメータ)以外のリクエストを送信できなかった。
        - 新しい文書の送信、更新、削除はできなかった。
        - サーバーが正しく応答を返すことができたかも分からない。
        - HTML前提だったため、サーバーからコンテンツのフォーマットを指定できない。

- 0.9から1.0へ移行する前の、名前のないバージョン(1.0とほぼ同じ)は電子メールのプロトコルなどを取り込んで行った。
    - リクエストにメソッド(GET)の追加
    - httpのバージョンが追加
    - ヘッダーが追加された(Host,User-Agent,Accept)
    - http Statusが追加された

- ヘッダーの仕組みはメールをベースに作られてる
- ブラウザがコンテンツの内容からContent-Typeを推測する → Content Sniffing
    - セキュリティホールになるのでオフにするのが現代の主流
        `X-Content-Type-Options: nosniff`
    - 例)
    ```
    HTTP/1.1 200 OK
    Content-Type: text/plain
    <br/>
    これはテキストファイルです。
    <script>alert("xss");</script>
    ```
    IEなどのブラウザはContent-Type:text/plainを無視してHTMLだと判断し、スクリプトが実行される
- マスター/スレーブ構成
    - 複数の機器を連携してシステムなどを動作させるにあたり、そのうちのひとつに全ての管理・制御を担当する「マスター」という役割をあて、残りをマスターに制御させる「スレーブ」とする方式
    - 主にデータベースサーバで行われる方式で、この場合、平常時はマスターがデータ読み込み・書き込みといった各処理を行い、スレーブはマスターの制御によって主にマスターのデータの複製（バックアップ）を行う。そしてマスターに障害が発生した際は、スレーブの中のひとつがマスターに切り替わって処理を継続する。
    - [引用]](https://www.fielding.co.jp/column/it_words/202003_1/#:~:text=%E2%91%A2%E3%83%9E%E3%82%B9%E3%82%BF%E3%83%BC%2F%E3%82%B9%E3%83%AC%E3%83%BC%E3%83%96%E6%A7%8B%E6%88%90,%E3%80%8C%E3%82%B9%E3%83%AC%E3%83%BC%E3%83%96%E3%80%8D%E3%81%A8%E3%81%99%E3%82%8B%E6%96%B9%E5%BC%8F%E3%80%82&text=%E3%81%9D%E3%81%97%E3%81%A6%E3%83%9E%E3%82%B9%E3%82%BF%E3%83%BC%E3%81%AB%E9%9A%9C%E5%AE%B3%E3%81%8C,%E3%81%A6%E5%87%A6%E7%90%86%E3%82%92%E7%B6%99%E7%B6%9A%E3%81%99%E3%82%8B%E3%80%82)
- HTTPメソッドは最初は沢山あった。1.0になって結構減った。LINKとかは1.1になってなくなった。
    - HTTP1.0で使われ、現在も残っている物
        - GET
        - HEAD
        - POST
        - PUT
        - DELETE
- RFCで定義されていない非標準のStatusコードがある
    - 444 Nginxがネットワークで問題があったときにエラーログへ吐くStatusコード
    - 999 Yahooがアクセスが増えた時にスクレイピングを禁止する(?)為にエラーを吐くときのコード
## 2章 HTTP/1.0のセマンティクス:ブラウザの基本機能の裏側
- FormのContent-Typeには`application/x-www-form-urlencoded` と `multipart/form-data`がある
    -　前者が普通のフォーム、後者はファイルが含まれている場合
- GETのパラメータが長い場合にURLの制限文字数を超えてしまう&アクセスログに全て残ってしまう
    - → サーバはリダイレクトさせ、リダイレクト先のHTMLに `<input type="hidden"/>`の形で渡す
    - SOAP形式、SAML認証、OpenID Connectなどで使われる方法
- コンテントネゴシエーション
    - 一つのリクエストの中でクライアントとサーバーがヘッダーを使って最適な設定を共有する仕組み
    - ex) ネゴシエーション対象: MIMEタイプ
            リクエストヘッダー: `Accept` ⇄ レスポンスヘッダ: `Content-Type`
    - その他、Accept-系とContent-系は相互に対応している (Accept-LanguageとContent-Languageなど)
- コンテンツ圧縮による通信速度向上は1992年の時点で定義されていた
    - コンテンツの圧縮-展開の速度は通信にかかる時間よりも少ないので全体的な通信速度が向上する
    - 利用料金にも影響していた。(ADSLや光回線が普及する前にはダイアルアップ回線による時間単位の従量課金性だった。現代のモバイル通信も従量課金性なので、圧縮によるデータ量削減は料金に影響する)
    - コンテンツ圧縮はヘッダー内だけで完結する。
        - クライアント側で受け入れ可能な圧縮形式を設定: `Accept-Encoding: deflate, gzip`
        - サーバーは送られてきたリストから、対応できるものがあれば圧縮、または事前に圧縮したコンテンツを返す: `Content-Encoding: gzip`
    - Googleはgzipよりも効率のいい`Brotli`を開発。
    - 圧縮の形式は、クライアント(ブラウザ)、サーバー、使われている言語の全てが対応していなければいけない。どれかが対応していない場合は他の形式にフォールバックされる(おそらくgzip)
- cookie: サーバーからクライアント(ブラウザ)にデータを保存しておいてもらう仕組み
    - サーバーからのレスポンスヘッダー: `Set-Cookie: LAST_ACCESS_DATE=Jul/31/2016`
    - クライアントのリクエストヘッダー(次回移行アクセス時): `Cookie: LAST_ACCESS_DATE=Jul/31/2016`
    - ステートレス(いつ誰がアクセスしてもリクエストが同じなら結果は同じ)なHTTPがあたかもステートフルに見せる仕組み
    - CookieはHTMLページだけでなく、そのページが参照している画像やXMLHttpRequestのレスポンスでも保存できる。
    - 別ドメインの画像ファイルやスクリプトを読み込んだ時に、そのCookieを受け入れるかどうかには制限がある(サードパーティCookie)
    - 発行元が訪れたサイト(ファーストパーティ)かそれ以外のサイト(サードパーティ)の二種類
    - ブラウザを閉じたら消えてしまうセッションクッキーと、期限が設定されていてブラウザを閉じても残る永続クッキーの2種類
    - クッキーはリクエスト時に毎回ヘッダーに設定される為、リクエスト、レスポンスの通信速度に影響する。最大要領は4KBにすべきとRFCにある。
    - セキュリティを高める為にヘッダーで制約を与える
        - Expires,Max-Age
            - Cookieの寿命。Max-Ageは秒。　
            - どちらも設定しなければ`セッションクッキー`
        - secure
            - https以外での通信ではクライアントからサーバーへクッキーを送らないようにする
- Basic認証/Digest認証
    - Basic:ユーザー名とパスワードをbase64エンコーディングする
    - Digest: ハッシュ関数(A→Bは簡単だが、B→Aは簡単に変換できない)を利用する
    - これらがあまり使われていない理由
        - 「特定のフォルダ以下を見せない」という使い方しかできず、ユーザーごとに表示する情報を変えるというのがやりづらい
        - 毎回の計算量が多い(Digestは特に)
        - 明示的なログオフができない
        - ログイン端末の識別ができない
- Cache-Control　~本当にキャッシュしないのは`no-store`のみ~
    - `public`: 同一コンピュータの複数ユーザ間でキャッシュの再利用を許可
    - `privte`: 同一コンピュータを使う別のユーザー間でキャッシュを再利用しない。
    - `max-age=n`: キャッシュの鮮度を秒で指定。86400を指定すると1日間の指定。それ以降は304　NotModifiedが帰って来た時のみキャッシュを利用する。
    - `no-cache`: キャッシュが有効かどうか毎回サーバーに問い合わせる。304　NotModifiedが帰って来た時のみキャッシュを利用する。max-age=0とほぼ同じ
    - `no-store`: キャッシュしない
    - `immutable`: コンテンツが決して変化しないことを伝える。Chrome非対応。
- Vary
    - PCで初回アクセス→キャッシュが保存される→2回目はSPでアクセス→SPではデバイス判別が行われず、キャッシュされたPC用HTMLが返されてしまう
    - ↑はググールのインデックス時にも発生してしまい、SEOにも影響する
    - Varyヘッダーをつけておけば、pc表示/SP表示が存在し、USerAgentにより切り替わることをブラウザ、クローラーに伝えることができる
- Referer
    - ユーザーがどの経路からウェブサイトへ到達したかをサーバーが把握する為に、クライアントがサーバーへ送るヘッダー 
    - Refererの設定の方法は三通りある
        - `Referer-Policy`ヘッダー: 
        - `<meta name="referer" content="設定値"`
        - `<a>`タグなどいくつかの要素の`refererpolicy`属性及、`rel="noreferer"`属性
        設定できる値
            - `no-referer`: 一切送らない
            - `no-referer-when-downgrade`: デフォルト動作と同じで、HTTPS→HTTPの時は送信しない
            - `same-origin`: 同一ドメイン内のリンクに対してのみ、リファラーを送信
            - `origin`: 詳細ページではなく、トップページからリンクされた物としてドメイン名だけを送信
                ex) amebloから楽天リンクを踏んだ時:`referer: https://ameblo.jp/` 
                `Referrer Policy: origin`が設定されている為、amebloのどの記事かは分からない
            - `strict-origin`: originと同じだが、HTTPS→HTTP時には送信しない
            - `origin-when-crossorigin`: 同じドメイン内ではフルのリファラーを、別ドメインではトップのドメイン名だけ表示
            - `strict-origin-when-crossorigin`: `origin-when-crossorigin`と同じだが、HTTPS→HTTP時には送信しない
            - `unsafe-url`: 常に送信
        - この他に、`Content-Security-Policy`でも設定できる
            ex) `Content-Security-Policy: referer origin`
            Content-Security-Policyは数多くのセキュリティに関する設定を一括で変更できるヘッダー

## 3章 Go言語によるHTTP/1.0クライアントの実装
- `io/ioutil`
    - io(ファイルの読み書き)に関するutility
    - そのうちdeprecatedになり、`io`パッケージと`os`パッケージに分割される
- http1.0ではbodyに任意のコンテンツを入れてPOSTすることができなかったが、1.1以降ではXMLHttpRequestを用いることで実現した。
- `multipart/form-data`は`Content-Type`の設定値の一つ
    - 1回のHTTP通信で、複数のMIMETypeを扱える
    - formでテキストとファイル同時に送信する時などに使える
    ```:html
        <form method="POST" action="/upload" enctype="multipart/form-data">
    ```
## 4章 HTTP/1.1のシンタックス:高速化と安全性を求めた拡張
- HTTP/1.1は高速化と安全性の向上
- Cache-Control(高速化)/TLS(安全性)
- `Connection:Keep-Alive`で通信速度が大幅に改善
    - Keep-Aliveがないと、毎リクエスト毎にTCP/IPがコネクションを張る。
        - あると、連続したリクエストを同じコネクション上で行う
        -  HTTP/2ではデフォルトで設定される
    - Connection:Closeで完了
    - Keep-Aliveの完了はクライアント/サーバーのうち、先に切断した方の通信が採用される   
- パケットが一往復する時間 → 1RTT(ラウンドトリップタイム)
    - TLSではハンドシェイクで2-RTT使う
        → Keep-Aliveを使うとn(2-RTT)減らせる
- パイプライニング
    - 最初のリクエストが完了する前に次のリクエストを送る。ブラウザベンダーがまとまらず、ほとんど使われていない。
        → その後の技術には継承されている。(HTTP2.0のストリーム)
- TLS(Transport Layer Security)
    - SSL(Security Socket Layer)はHTTP1.0の時からv3.0が存在した
    - HTTP以外にもSMTPのTLS版、SMTPSでも使われている
    - HTTP1.0/1.1以外では自身が解釈していないプロトコルを扱えない。WebSocketやHTTP2などの新しいプロトコルも、TLSによる安全な通信によってスムーズに導入された。
- TLSの暗号化
    - 暗号化の方法(アルゴリズム)が公開(OSS)されていても、安全に通信できることが前提となっている。
    - 暗号化方式はオープンだが、使うデータ(鍵)は別で用意する。
    - 鍵の形式
        - 共通鍵方式(対象暗号) → 高速
            - 鍵をかけるのと開けるので同じ鍵を使う。共有しておく。
        - 公開鍵暗号(非対称暗号) → より安全
            - 暗号化する鍵: 公開鍵(鍵と言うより、南京錠のイメージ)
            - 複合化する鍵: 秘密鍵 → 暗号化方式のデファクトスタンダードはRSA2048(2017年時点)
        - デジタル署名(公開鍵の応用)
    - TLSでは共通鍵方式と公開鍵方式を組み合わせている
        公開鍵方式は計算量が多いので、最初は公開鍵方式、その後は共通鍵方式で高速に通信する
## 5章 HTTP/1.1のセマンティクス:広がるのHTTPの用途
- RPC(Remote Procedure Call)
    - 別のコンピュータにある機能をあたかも自分のコンピュータ内であるかのように呼び出す
    - Procedure: 各言語が用意しているメソッドの塊(サブルーチンとも言う)
- XML-RPC → XMLだからシンプル
- SOAP(Simple Object Access Protocol) →シンプルじゃない、、
    - データ表現フォーマットの一つ。SOAP-RPCがある。
    - HTTPの中にミニHTTPのような構造をもち、SMTPなどとも連携できる→複雑さの原因に
    - WSDL(SOAPのインターフェース定義)
    - 最新versionは2007年
- JSON-RPC → SOAPとは対照的にシンプルにした
## 6章 Go言語によるHTTP1.1クライアントの実装
- 証明書の作成
    1. OpenSSLコマンドで秘密鍵の作成
    2. 証明書要求ファイルを作成
    3. (1で作った秘密鍵を使って)証明書要求ファイルに署名 → 本来は認証局がやる。オレオレ証明書なら自分でやる。
## 7章 HTTP/2、HTTP/3のシンタックス:プロトコルの再定義
- SPDY(スピーディ)
    - GoogleがHTTPの代替として開発したプロトコル。HTTP/2の基となった。
- HTTP/2 → 高速化
    - ストリーム(HTTP1.1で言うパイプライン)
    - サーバーサイドプッシュ
    - ヘッダーの圧縮 (HPACKと言う形式で圧縮)
    - テキストベースからバイナリベースへ
    - 各データはフレームと呼ばれる単位で送受信
    - HTTP/1では1リクエストが1つのTCPソケットを占有
    - HTTP/2はストリームを使って、仮想のTCPソケットをたくさん作って通信する
- QUIC(クイック)
    - HTTP/3の基となった。Googleが開発。
    - HTTP/2 → TCPソケットの上に実装
        - QUICはUDPベースで実装してさらなる高速化
    - DTLS 
        - TLSの機能を最初から持っているのでハンドシェイクがいらない。→高速化
        - HTTPSではTCPのハンドシェイク+TSLのハンドシェイクが必要
- WebRTC
    - UDP上で動く(トランスポート層)→再送、エラー処理をしない
    - シグナリング: 相手のコンピュータを探す
    - NAT越え: ルータ内部のプライベートアドレスしか持たないコンピュータで使われるブラウザのために必要
※ 通信時間 = データサイズ ÷ 通信速度
## 8章 HTTP/2のセマンティクス:新しいユースケース
- セマンティックウェブ
    - 表面的なテキスト/文書ではなく「意味」を扱えるようにしてウェブの可能性を広げる動き
- AMP
    - ページ構成を固定してページの高速化 → 固定化しているのでCDN化させやすい
    - クローラがAMPページだと判断すると、GoogleのCDNにキャッシュされる
## 9章 Go言語によるHTTP/2、HTML5のプロトコルの実装
## 10章 クライアント視点で見るRESTful API
## 11章 JavaScriptによるブラウザからの動的なHTTPリクエスト
## 12章 ウェブアプリケーションの基礎
## 13章 クラウド時代のHTTP:ウェブを強くするさまざまな技術
- プロキシサーバー
    - CDN
    - WAF(Web Application Firewall)
    - ロードバランサー
        - 前段でリクエストを受け、背後にある複数のインスタンスへリクエストを割り振る。
        - 割り振りかたはLBそれぞれ。ランダム、ラウンドロビン方式など
        - ヘルスチェック、負荷が増えたらインスタンスを増やしたりしてくれる
        - 接続ドレイン
            - ロードバランサーの接続変更後、新規リクエストは新しいバージョンに流し、古いものは完了するまで待つようにする
    - API Gateway
        - APIの設計支援 → OpenAPIのインポートや、ドキュメント作成
        - APIのバージョン管理
        - 認証/ロギング・モニタリング
## 14章 セキュリティ:ブラウザを守るHTTPの機能